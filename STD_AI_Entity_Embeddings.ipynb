{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STD_AI_Entity_Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rTbaoFhwmiTh_NiDtUgmqlBaih5RsRDt",
      "authorship_tag": "ABX9TyMnn7Rh6qwZeR+TnX5D3XZJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranshurastogi29/how-effective-are-std-drugs/blob/master/STD_AI_Entity_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqvuwdWOJT3g",
        "colab_type": "code",
        "outputId": "8df89dbc-833e-42d0-e8fb-634cc3f60201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import skew, norm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k68KUOIT9nj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics, preprocessing\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kYRyWoL96HC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def auc(y_true, y_pred):\n",
        "    def fallback_auc(y_true, y_pred):\n",
        "        try:\n",
        "            return metrics.roc_auc_score(y_true, y_pred)\n",
        "        except:\n",
        "            return 0.5\n",
        "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)\n",
        "\n",
        "def create_model(data, catcols):    \n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    for c in catcols:\n",
        "        num_unique_values = int(data[c].nunique())\n",
        "        embed_dim = 180\n",
        "        inp = layers.Input(shape=(1,))\n",
        "        out = layers.Embedding(num_unique_values, embed_dim, name=c)(inp)\n",
        "        out = layers.SpatialDropout1D(0.3)(out)\n",
        "        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
        "        inputs.append(inp)\n",
        "        outputs.append(out)\n",
        "\n",
        "    inp1 = layers.Input(shape=(2,))\n",
        "    x = layers.Dense(2, activation=\"sigmoid\")(inp)\n",
        "    outputs.append(x)\n",
        "    x = layers.Concatenate()(outputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = layers.Dense(300, activation=\"sigmoid\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = layers.Dense(300, activation=\"sigmoid\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    y = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs=[inputs,inp1], outputs=y)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LGjqs4favBXi",
        "outputId": "4049b657-0d98-4f52-9fd6-21b68efd1687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/train.csv')\n",
        "df1 = pd.read_csv('/content/drive/My Drive/test.csv')\n",
        "df = df.drop(columns=['drug_approved_by_UIC','patient_id'])\n",
        "df1 = df1.drop(columns=['drug_approved_by_UIC','patient_id'])\n",
        "df1['base_score'] = -1\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name_of_drug</th>\n",
              "      <th>use_case_for_drug</th>\n",
              "      <th>review_by_patient</th>\n",
              "      <th>effectiveness_rating</th>\n",
              "      <th>number_of_times_prescribed</th>\n",
              "      <th>base_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Valsartan</td>\n",
              "      <td>Left Ventricular Dysfunction</td>\n",
              "      <td>\"It has no side effect, I take it in combinati...</td>\n",
              "      <td>9</td>\n",
              "      <td>27</td>\n",
              "      <td>8.022969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>\"My son is halfway through his fourth week of ...</td>\n",
              "      <td>8</td>\n",
              "      <td>192</td>\n",
              "      <td>7.858458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lybrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>6.341969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Buprenorphine / naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>\"Suboxone has completely turned my life around...</td>\n",
              "      <td>9</td>\n",
              "      <td>37</td>\n",
              "      <td>6.590176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cialis</td>\n",
              "      <td>Benign Prostatic Hyperplasia</td>\n",
              "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "      <td>6.144782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               name_of_drug  ... base_score\n",
              "0                 Valsartan  ...   8.022969\n",
              "1                Guanfacine  ...   7.858458\n",
              "2                    Lybrel  ...   6.341969\n",
              "3  Buprenorphine / naloxone  ...   6.590176\n",
              "4                    Cialis  ...   6.144782\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSV5Payc-f2g",
        "colab_type": "code",
        "outputId": "ba97c6ca-3f4f-4945-a8ae-dd7c4b7d5b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.preprocessing import  PowerTransformer,QuantileTransformer\n",
        "rng = np.random.RandomState(24546)\n",
        "qt =  PowerTransformer()\n",
        "X = df.number_of_times_prescribed.values.reshape(-1,1)\n",
        "#X = qt.fit_transform(X)\n",
        "qt1 = QuantileTransformer(n_quantiles=500, output_distribution='normal',\n",
        "                         random_state=rng)\n",
        "X = qt.fit_transform(X)\n",
        "print('this is done')\n",
        "df['number_of_times_prescribed'] = pd.Series(X.reshape(1,-1)[0])\n",
        "X = df1.number_of_times_prescribed.values.reshape(-1,1)\n",
        "#X = qt.fit_transform(X)\n",
        "qt1 = QuantileTransformer(n_quantiles=500, output_distribution='normal',\n",
        "                         random_state=rng)\n",
        "X = qt.fit_transform(X)\n",
        "print('this is done')\n",
        "df1['number_of_times_prescribed'] = pd.Series(X.reshape(1,-1)[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is done\n",
            "this is done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpWEjBEj35dN",
        "colab_type": "code",
        "outputId": "6e33fd63-4f1b-4e6d-f032-84680cabd117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.preprocessing import  PowerTransformer,QuantileTransformer\n",
        "rng = np.random.RandomState(24546)\n",
        "qt =  PowerTransformer()\n",
        "X = df.effectiveness_rating.values.reshape(-1,1)\n",
        "X = qt.fit_transform(X)\n",
        "qt1 = QuantileTransformer(n_quantiles=500, output_distribution='normal',\n",
        "                         random_state=rng)\n",
        "X = qt1.fit_transform(X)\n",
        "print('this is done')\n",
        "df['effectiveness_rating'] = pd.Series(X.reshape(1,-1)[0])\n",
        "X = df1.effectiveness_rating.values.reshape(-1,1)\n",
        "X = qt.fit_transform(X)\n",
        "qt1 = QuantileTransformer(n_quantiles=500, output_distribution='normal',\n",
        "                         random_state=rng)\n",
        "X = qt1.fit_transform(X)\n",
        "print('this is done')\n",
        "df1['effectiveness_rating'] = pd.Series(X.reshape(1,-1)[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is done\n",
            "this is done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ngxPffc4NwE",
        "colab_type": "code",
        "outputId": "f402d3d3-89a1-4d1b-f4dc-19c4b9372899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.preprocessing import  PowerTransformer,QuantileTransformer\n",
        "rng = np.random.RandomState(24546)\n",
        "qt =  PowerTransformer()\n",
        "X = df.base_score.values.reshape(-1,1)\n",
        "#X = qt.fit_transform(X)\n",
        "qt = QuantileTransformer(n_quantiles=500, output_distribution='normal',\n",
        "                         random_state=rng)\n",
        "X = qt.fit_transform(X)\n",
        "print('this is done')\n",
        "df['base_score'] = pd.Series(X.reshape(1,-1)[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn-04_F4zj1g",
        "colab_type": "code",
        "outputId": "20a51900-cea1-46b0-ba46-2e5063f6afca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name_of_drug</th>\n",
              "      <th>review_by_patient</th>\n",
              "      <th>number_of_times_prescribed</th>\n",
              "      <th>use_case_for_drug</th>\n",
              "      <th>effectiveness_rating</th>\n",
              "      <th>base_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mirtazapine</td>\n",
              "      <td>\"I&amp;#039;ve tried a few antidepressants over th...</td>\n",
              "      <td>0.271432</td>\n",
              "      <td>Depression</td>\n",
              "      <td>5.199338</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Contrave</td>\n",
              "      <td>\"Contrave combines drugs that were used for al...</td>\n",
              "      <td>0.680894</td>\n",
              "      <td>Weight Loss</td>\n",
              "      <td>0.256461</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zyclara</td>\n",
              "      <td>\"4 days in on first 2 weeks.  Using on arms an...</td>\n",
              "      <td>-0.159650</td>\n",
              "      <td>Keratosis</td>\n",
              "      <td>-0.717694</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Methadone</td>\n",
              "      <td>\"Ive been on Methadone for over ten years and ...</td>\n",
              "      <td>0.231879</td>\n",
              "      <td>Opiate Withdrawal</td>\n",
              "      <td>-0.324591</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ambien</td>\n",
              "      <td>\"Ditto on rebound sleepless when discontinued....</td>\n",
              "      <td>0.892369</td>\n",
              "      <td>Insomnia</td>\n",
              "      <td>-1.013919</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10755</th>\n",
              "      <td>Chantix</td>\n",
              "      <td>\"I took chantix a little over a month. It made...</td>\n",
              "      <td>-1.358755</td>\n",
              "      <td>Smoking Cessation</td>\n",
              "      <td>-5.199338</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10756</th>\n",
              "      <td>Armodafinil</td>\n",
              "      <td>\"This medicine kept me from sleeping the whole...</td>\n",
              "      <td>0.102778</td>\n",
              "      <td>Narcolepsy</td>\n",
              "      <td>-5.199338</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10757</th>\n",
              "      <td>Tamoxifen</td>\n",
              "      <td>\"I have taken Tamoxifen for 5 years. Side effe...</td>\n",
              "      <td>0.870839</td>\n",
              "      <td>Breast Cancer, Prevention</td>\n",
              "      <td>5.199338</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10758</th>\n",
              "      <td>Levonorgestrel</td>\n",
              "      <td>\"I&amp;#039;m married, 34 years old and I have no ...</td>\n",
              "      <td>-0.618579</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>-0.105686</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10759</th>\n",
              "      <td>Arthrotec</td>\n",
              "      <td>\"It works!!!\"</td>\n",
              "      <td>0.934179</td>\n",
              "      <td>Sciatica</td>\n",
              "      <td>0.256461</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10760 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         name_of_drug  ... base_score\n",
              "0         Mirtazapine  ...         -1\n",
              "1            Contrave  ...         -1\n",
              "2             Zyclara  ...         -1\n",
              "3           Methadone  ...         -1\n",
              "4              Ambien  ...         -1\n",
              "...               ...  ...        ...\n",
              "10755         Chantix  ...         -1\n",
              "10756     Armodafinil  ...         -1\n",
              "10757       Tamoxifen  ...         -1\n",
              "10758  Levonorgestrel  ...         -1\n",
              "10759       Arthrotec  ...         -1\n",
              "\n",
              "[10760 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQbH43mBjHtM",
        "colab_type": "code",
        "outputId": "7e9336a5-978e-412b-d6db-ee281d0a5c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name_of_drug</th>\n",
              "      <th>use_case_for_drug</th>\n",
              "      <th>review_by_patient</th>\n",
              "      <th>effectiveness_rating</th>\n",
              "      <th>number_of_times_prescribed</th>\n",
              "      <th>base_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Valsartan</td>\n",
              "      <td>Left Ventricular Dysfunction</td>\n",
              "      <td>\"It has no side effect, I take it in combinati...</td>\n",
              "      <td>0.243504</td>\n",
              "      <td>0.451782</td>\n",
              "      <td>0.757254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>\"My son is halfway through his fourth week of ...</td>\n",
              "      <td>-0.118323</td>\n",
              "      <td>2.360086</td>\n",
              "      <td>0.632244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lybrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
              "      <td>-0.602120</td>\n",
              "      <td>0.063449</td>\n",
              "      <td>-0.366994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Buprenorphine / naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>\"Suboxone has completely turned my life around...</td>\n",
              "      <td>0.243504</td>\n",
              "      <td>0.730172</td>\n",
              "      <td>-0.127849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cialis</td>\n",
              "      <td>Benign Prostatic Hyperplasia</td>\n",
              "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
              "      <td>-1.013919</td>\n",
              "      <td>0.866803</td>\n",
              "      <td>-0.585413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32160</th>\n",
              "      <td>Cymbalta</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>\"I have been taking Cymbalta for 15 months now...</td>\n",
              "      <td>0.243504</td>\n",
              "      <td>1.562625</td>\n",
              "      <td>0.108212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32161</th>\n",
              "      <td>Nexplanon</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"I have had the Nexplanon since Dec. 27, 2016 ...</td>\n",
              "      <td>-0.474322</td>\n",
              "      <td>-2.101707</td>\n",
              "      <td>-5.199338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32162</th>\n",
              "      <td>Venlafaxine</td>\n",
              "      <td>Panic Disorde</td>\n",
              "      <td>\"Had panic attacks and social anxiety starting...</td>\n",
              "      <td>0.243504</td>\n",
              "      <td>0.385470</td>\n",
              "      <td>-0.460314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32163</th>\n",
              "      <td>Fluoxetine</td>\n",
              "      <td>Obsessive Compulsive Disorde</td>\n",
              "      <td>\"I have been off Prozac for about 4 weeks now....</td>\n",
              "      <td>-0.118323</td>\n",
              "      <td>0.276815</td>\n",
              "      <td>0.725118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32164</th>\n",
              "      <td>Orencia</td>\n",
              "      <td>Rheumatoid Arthritis</td>\n",
              "      <td>\"Limited improvement after 4 months, developed...</td>\n",
              "      <td>-1.013919</td>\n",
              "      <td>0.680275</td>\n",
              "      <td>0.872553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32165 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   name_of_drug  ... base_score\n",
              "0                     Valsartan  ...   0.757254\n",
              "1                    Guanfacine  ...   0.632244\n",
              "2                        Lybrel  ...  -0.366994\n",
              "3      Buprenorphine / naloxone  ...  -0.127849\n",
              "4                        Cialis  ...  -0.585413\n",
              "...                         ...  ...        ...\n",
              "32160                  Cymbalta  ...   0.108212\n",
              "32161                 Nexplanon  ...  -5.199338\n",
              "32162               Venlafaxine  ...  -0.460314\n",
              "32163                Fluoxetine  ...   0.725118\n",
              "32164                   Orencia  ...   0.872553\n",
              "\n",
              "[32165 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJOrMQhe-dEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1['base_score'] = -1\n",
        "train = df[['name_of_drug', 'use_case_for_drug','effectiveness_rating','number_of_times_prescribed','base_score']]\n",
        "test = df1[['name_of_drug', 'use_case_for_drug','effectiveness_rating','number_of_times_prescribed','base_score']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqIQ34hmlgFM",
        "colab_type": "code",
        "outputId": "9f29e80b-a664-4ee9-bf2d-3df6549d6978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name_of_drug</th>\n",
              "      <th>use_case_for_drug</th>\n",
              "      <th>effectiveness_rating</th>\n",
              "      <th>number_of_times_prescribed</th>\n",
              "      <th>base_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mirtazapine</td>\n",
              "      <td>Depression</td>\n",
              "      <td>5.199338</td>\n",
              "      <td>0.271432</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Contrave</td>\n",
              "      <td>Weight Loss</td>\n",
              "      <td>0.256461</td>\n",
              "      <td>0.680894</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zyclara</td>\n",
              "      <td>Keratosis</td>\n",
              "      <td>-0.717694</td>\n",
              "      <td>-0.159650</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Methadone</td>\n",
              "      <td>Opiate Withdrawal</td>\n",
              "      <td>-0.324591</td>\n",
              "      <td>0.231879</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ambien</td>\n",
              "      <td>Insomnia</td>\n",
              "      <td>-1.013919</td>\n",
              "      <td>0.892369</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10755</th>\n",
              "      <td>Chantix</td>\n",
              "      <td>Smoking Cessation</td>\n",
              "      <td>-5.199338</td>\n",
              "      <td>-1.358755</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10756</th>\n",
              "      <td>Armodafinil</td>\n",
              "      <td>Narcolepsy</td>\n",
              "      <td>-5.199338</td>\n",
              "      <td>0.102778</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10757</th>\n",
              "      <td>Tamoxifen</td>\n",
              "      <td>Breast Cancer, Prevention</td>\n",
              "      <td>5.199338</td>\n",
              "      <td>0.870839</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10758</th>\n",
              "      <td>Levonorgestrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>-0.105686</td>\n",
              "      <td>-0.618579</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10759</th>\n",
              "      <td>Arthrotec</td>\n",
              "      <td>Sciatica</td>\n",
              "      <td>0.256461</td>\n",
              "      <td>0.934179</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10760 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         name_of_drug  ... base_score\n",
              "0         Mirtazapine  ...         -1\n",
              "1            Contrave  ...         -1\n",
              "2             Zyclara  ...         -1\n",
              "3           Methadone  ...         -1\n",
              "4              Ambien  ...         -1\n",
              "...               ...  ...        ...\n",
              "10755         Chantix  ...         -1\n",
              "10756     Armodafinil  ...         -1\n",
              "10757       Tamoxifen  ...         -1\n",
              "10758  Levonorgestrel  ...         -1\n",
              "10759       Arthrotec  ...         -1\n",
              "\n",
              "[10760 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xZMpphI4pMm",
        "colab_type": "code",
        "outputId": "af442ccb-7788-453f-bd7e-4b52a7834504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name_of_drug</th>\n",
              "      <th>use_case_for_drug</th>\n",
              "      <th>effectiveness_rating</th>\n",
              "      <th>number_of_times_prescribed</th>\n",
              "      <th>base_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Valsartan</td>\n",
              "      <td>Left Ventricular Dysfunction</td>\n",
              "      <td>0.243504</td>\n",
              "      <td>0.451782</td>\n",
              "      <td>0.757254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>-0.118323</td>\n",
              "      <td>2.360086</td>\n",
              "      <td>0.632244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lybrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>-0.602120</td>\n",
              "      <td>0.063449</td>\n",
              "      <td>-0.366994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Buprenorphine / naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>0.243504</td>\n",
              "      <td>0.730172</td>\n",
              "      <td>-0.127849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cialis</td>\n",
              "      <td>Benign Prostatic Hyperplasia</td>\n",
              "      <td>-1.013919</td>\n",
              "      <td>0.866803</td>\n",
              "      <td>-0.585413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32160</th>\n",
              "      <td>Cymbalta</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>0.243504</td>\n",
              "      <td>1.562625</td>\n",
              "      <td>0.108212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32161</th>\n",
              "      <td>Nexplanon</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>-0.474322</td>\n",
              "      <td>-2.101707</td>\n",
              "      <td>-5.199338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32162</th>\n",
              "      <td>Venlafaxine</td>\n",
              "      <td>Panic Disorde</td>\n",
              "      <td>0.243504</td>\n",
              "      <td>0.385470</td>\n",
              "      <td>-0.460314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32163</th>\n",
              "      <td>Fluoxetine</td>\n",
              "      <td>Obsessive Compulsive Disorde</td>\n",
              "      <td>-0.118323</td>\n",
              "      <td>0.276815</td>\n",
              "      <td>0.725118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32164</th>\n",
              "      <td>Orencia</td>\n",
              "      <td>Rheumatoid Arthritis</td>\n",
              "      <td>-1.013919</td>\n",
              "      <td>0.680275</td>\n",
              "      <td>0.872553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32165 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   name_of_drug  ... base_score\n",
              "0                     Valsartan  ...   0.757254\n",
              "1                    Guanfacine  ...   0.632244\n",
              "2                        Lybrel  ...  -0.366994\n",
              "3      Buprenorphine / naloxone  ...  -0.127849\n",
              "4                        Cialis  ...  -0.585413\n",
              "...                         ...  ...        ...\n",
              "32160                  Cymbalta  ...   0.108212\n",
              "32161                 Nexplanon  ...  -5.199338\n",
              "32162               Venlafaxine  ...  -0.460314\n",
              "32163                Fluoxetine  ...   0.725118\n",
              "32164                   Orencia  ...   0.872553\n",
              "\n",
              "[32165 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5aDj5fj0Awl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.concat([train, test]).reset_index(drop=True)\n",
        "features = [x for x in train.columns if x not in ['effectiveness_rating','number_of_times_prescribed','base_score']]\n",
        "\n",
        "out = []\n",
        "for feat in features:\n",
        "    lbl_enc = preprocessing.LabelEncoder()\n",
        "    data[feat] = lbl_enc.fit_transform(data[feat].fillna(-1).astype(str).values)\n",
        "    out.append(lbc_enc)\n",
        "import pickle\n",
        "saved_embeddings_fname = \"/content/drive/My Drive/labels.pickle\"\n",
        "with open(saved_embeddings_fname, 'wb') as f:\n",
        "    pickle.dump(out, f, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpJMv-y10EKx",
        "colab_type": "code",
        "outputId": "5789200b-331b-412e-bfdf-b9ed616e9fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data.name_of_drug.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F3QKG6pjghi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['name_of_drug', 'use_case_for_drug']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GHL5XBH_HFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = data[data.base_score != -1].reset_index(drop=True)\n",
        "test = data[data.base_score == -1].reset_index(drop=True)\n",
        "test_data = [test.loc[:, features].values[:, k] for k in range(test.loc[:, features].values.shape[1])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42j9PeQnAULW",
        "colab_type": "code",
        "outputId": "4fa690c6-3a17-4268-bffd-70235d889008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "oof_preds = np.zeros((len(train)))\n",
        "test_preds = np.zeros((len(test)))\n",
        "fold = 0\n",
        "skf = KFold(n_splits=10)\n",
        "for train_index, test_index in skf.split(train, train.base_score.values):\n",
        "    print('fold',fold)\n",
        "    X_train, X_test = train.iloc[train_index, :], train.iloc[test_index, :]\n",
        "    X_train = X_train.reset_index(drop=True)\n",
        "    X_test = X_test.reset_index(drop=True)\n",
        "    y_train, y_test = X_train.base_score.values, X_test.base_score.values\n",
        "    model = create_model(data, features)\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])\n",
        "    X_t = [X_train.loc[:, features].values[:, k] for k in range(X_train.loc[:, features].values.shape[1])]\n",
        "    X_tt =  [X_test.loc[:, features].values[:, k] for k in range(X_test.loc[:, features].values.shape[1])]\n",
        "    \n",
        "    es = callbacks.EarlyStopping(monitor='mae', min_delta=0.0001, patience=5,\n",
        "                                 verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "    rlr = callbacks.ReduceLROnPlateau(monitor='mae', factor=0.5,\n",
        "                                      patience=3, min_lr=1e-7, mode='min', verbose=1)\n",
        "    \n",
        "    x_t = X_train[['effectiveness_rating','number_of_times_prescribed']].values\n",
        "    x_tt = X_test[['effectiveness_rating','number_of_times_prescribed']].values\n",
        "    model.fit([X_t,x_t],\n",
        "              y_train,\n",
        "              validation_data = ([X_tt,x_tt],y_test),\n",
        "              verbose=1,\n",
        "              batch_size=1024,\n",
        "              callbacks=[es,rlr],\n",
        "              epochs=100\n",
        "             )\n",
        "    valid_fold_preds = model.predict([X_tt,x_tt])\n",
        "    test_fold_preds = model.predict([test_data,\n",
        "                        test[['effectiveness_rating','number_of_times_prescribed']].values])\n",
        "    oof_preds[test_index] = valid_fold_preds.ravel()\n",
        "    test_preds += test_fold_preds.ravel()\n",
        "    fold = fold + 1\n",
        "    K.clear_session()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 1.3088 - mae: 0.9031 - val_loss: 1.1548 - val_mae: 0.8324 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1910 - mae: 0.8603 - val_loss: 1.1145 - val_mae: 0.8164 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1237 - mae: 0.8330 - val_loss: 1.0819 - val_mae: 0.8025 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0780 - mae: 0.8163 - val_loss: 1.0744 - val_mae: 0.7989 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0522 - mae: 0.8050 - val_loss: 1.0710 - val_mae: 0.7971 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0382 - mae: 0.7978 - val_loss: 1.0697 - val_mae: 0.7963 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0292 - mae: 0.7940 - val_loss: 1.0689 - val_mae: 0.7959 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0219 - mae: 0.7923 - val_loss: 1.0687 - val_mae: 0.7957 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0185 - mae: 0.7901 - val_loss: 1.0688 - val_mae: 0.7957 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0178 - mae: 0.7890 - val_loss: 1.0685 - val_mae: 0.7956 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0111 - mae: 0.7873 - val_loss: 1.0682 - val_mae: 0.7955 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0136 - mae: 0.7873 - val_loss: 1.0684 - val_mae: 0.7954 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0114 - mae: 0.7860 - val_loss: 1.0679 - val_mae: 0.7954 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0035 - mae: 0.7852 - val_loss: 1.0685 - val_mae: 0.7957 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0124 - mae: 0.7850 - val_loss: 1.0698 - val_mae: 0.7964 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0052 - mae: 0.7845 - val_loss: 1.0696 - val_mae: 0.7964 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 1.0097 - mae: 0.7849 - val_loss: 1.0703 - val_mae: 0.7967 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0102 - mae: 0.7851 - val_loss: 1.0711 - val_mae: 0.7973 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0075 - mae: 0.7835 - val_loss: 1.0715 - val_mae: 0.7973 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0006 - mae: 0.7823 - val_loss: 1.0729 - val_mae: 0.7984 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0052 - mae: 0.7831 - val_loss: 1.0767 - val_mae: 0.7994 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9998 - mae: 0.7824 - val_loss: 1.0821 - val_mae: 0.8007 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0030 - mae: 0.7820 - val_loss: 1.0800 - val_mae: 0.8006 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9990 - mae: 0.7819 - val_loss: 1.0830 - val_mae: 0.8010 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0036 - mae: 0.7809 - val_loss: 1.0899 - val_mae: 0.8043 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9974 - mae: 0.7808 - val_loss: 1.0835 - val_mae: 0.8013 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9991 - mae: 0.7801 - val_loss: 1.0837 - val_mae: 0.8013 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9995 - mae: 0.7803 - val_loss: 1.0899 - val_mae: 0.8039 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9990 - mae: 0.7796 - val_loss: 1.0843 - val_mae: 0.8021 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9965 - mae: 0.7795 - val_loss: 1.0868 - val_mae: 0.8026 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9992 - mae: 0.7797 - val_loss: 1.0841 - val_mae: 0.8013 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9972 - mae: 0.7791 - val_loss: 1.0924 - val_mae: 0.8039 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9951 - mae: 0.7793 - val_loss: 1.0897 - val_mae: 0.8018 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9975 - mae: 0.7795 - val_loss: 1.0982 - val_mae: 0.8053 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9920 - mae: 0.7776 - val_loss: 1.0824 - val_mae: 0.8009 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9892 - mae: 0.7783 - val_loss: 1.0926 - val_mae: 0.8046 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9966 - mae: 0.7775 - val_loss: 1.0920 - val_mae: 0.8046 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9917 - mae: 0.7772 - val_loss: 1.0893 - val_mae: 0.8038 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9956 - mae: 0.7767 - val_loss: 1.0849 - val_mae: 0.8023 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9857 - mae: 0.7763 - val_loss: 1.0918 - val_mae: 0.8043 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9904 - mae: 0.7768 - val_loss: 1.0919 - val_mae: 0.8045 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9881 - mae: 0.7758 - val_loss: 1.0889 - val_mae: 0.8035 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9955 - mae: 0.7764 - val_loss: 1.0913 - val_mae: 0.8044 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9907 - mae: 0.7764 - val_loss: 1.0887 - val_mae: 0.8039 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9913 - mae: 0.7757\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9913 - mae: 0.7757 - val_loss: 1.0903 - val_mae: 0.8037 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 0.9855 - mae: 0.7746 - val_loss: 1.0936 - val_mae: 0.8050 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9915 - mae: 0.7744 - val_loss: 1.0896 - val_mae: 0.8039 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9867 - mae: 0.7745 - val_loss: 1.0929 - val_mae: 0.8045 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9914 - mae: 0.7743 - val_loss: 1.0937 - val_mae: 0.8052 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9873 - mae: 0.7741 - val_loss: 1.0867 - val_mae: 0.8024 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9927 - mae: 0.7743 - val_loss: 1.0886 - val_mae: 0.8029 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9866 - mae: 0.7742 - val_loss: 1.0859 - val_mae: 0.8023 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 0.9859 - mae: 0.7746\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9862 - mae: 0.7741 - val_loss: 1.0845 - val_mae: 0.8019 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9858 - mae: 0.7740 - val_loss: 1.0899 - val_mae: 0.8040 - lr: 2.5000e-04\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9873 - mae: 0.7735 - val_loss: 1.0901 - val_mae: 0.8040 - lr: 2.5000e-04\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9841 - mae: 0.7732 - val_loss: 1.0901 - val_mae: 0.8039 - lr: 2.5000e-04\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9825 - mae: 0.7732 - val_loss: 1.0880 - val_mae: 0.8034 - lr: 2.5000e-04\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9876 - mae: 0.7731 - val_loss: 1.0904 - val_mae: 0.8042 - lr: 2.5000e-04\n",
            "Epoch 59/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9772 - mae: 0.7705\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9831 - mae: 0.7732 - val_loss: 1.0883 - val_mae: 0.8036 - lr: 2.5000e-04\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9845 - mae: 0.7725 - val_loss: 1.0917 - val_mae: 0.8047 - lr: 1.2500e-04\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9857 - mae: 0.7730 - val_loss: 1.0902 - val_mae: 0.8040 - lr: 1.2500e-04\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9874 - mae: 0.7727 - val_loss: 1.0915 - val_mae: 0.8044 - lr: 1.2500e-04\n",
            "Epoch 63/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9847 - mae: 0.7726\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9840 - mae: 0.7727 - val_loss: 1.0912 - val_mae: 0.8042 - lr: 1.2500e-04\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9846 - mae: 0.7729 - val_loss: 1.0915 - val_mae: 0.8044 - lr: 6.2500e-05\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9784 - mae: 0.7722 - val_loss: 1.0912 - val_mae: 0.8043 - lr: 6.2500e-05\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9808 - mae: 0.7721 - val_loss: 1.0909 - val_mae: 0.8043 - lr: 6.2500e-05\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9837 - mae: 0.7722 - val_loss: 1.0917 - val_mae: 0.8045 - lr: 6.2500e-05\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9816 - mae: 0.7723 - val_loss: 1.0916 - val_mae: 0.8045 - lr: 6.2500e-05\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9809 - mae: 0.7723\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9809 - mae: 0.7723 - val_loss: 1.0911 - val_mae: 0.8043 - lr: 6.2500e-05\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9828 - mae: 0.7724 - val_loss: 1.0915 - val_mae: 0.8044 - lr: 3.1250e-05\n",
            "Epoch 71/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 0.9749 - mae: 0.7704Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9860 - mae: 0.7723 - val_loss: 1.0918 - val_mae: 0.8046 - lr: 3.1250e-05\n",
            "Epoch 00071: early stopping\n",
            "fold 1\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 1.3019 - mae: 0.9019 - val_loss: 1.3003 - val_mae: 0.8993 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1899 - mae: 0.8569 - val_loss: 1.1818 - val_mae: 0.8513 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.1144 - mae: 0.8300 - val_loss: 1.1061 - val_mae: 0.8178 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0740 - mae: 0.8133 - val_loss: 1.0745 - val_mae: 0.8021 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0516 - mae: 0.8022 - val_loss: 1.0655 - val_mae: 0.7970 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0440 - mae: 0.7993 - val_loss: 1.0610 - val_mae: 0.7943 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0295 - mae: 0.7937 - val_loss: 1.0598 - val_mae: 0.7932 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0280 - mae: 0.7924 - val_loss: 1.0590 - val_mae: 0.7925 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0201 - mae: 0.7907 - val_loss: 1.0587 - val_mae: 0.7921 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0205 - mae: 0.7895 - val_loss: 1.0586 - val_mae: 0.7920 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0104 - mae: 0.7868 - val_loss: 1.0584 - val_mae: 0.7918 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0159 - mae: 0.7868 - val_loss: 1.0587 - val_mae: 0.7918 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0158 - mae: 0.7862 - val_loss: 1.0585 - val_mae: 0.7917 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0091 - mae: 0.7853 - val_loss: 1.0592 - val_mae: 0.7920 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.0062 - mae: 0.7842 - val_loss: 1.0601 - val_mae: 0.7925 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0061 - mae: 0.7846 - val_loss: 1.0609 - val_mae: 0.7929 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0113 - mae: 0.7844 - val_loss: 1.0655 - val_mae: 0.7952 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0079 - mae: 0.7834 - val_loss: 1.0657 - val_mae: 0.7955 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0128 - mae: 0.7835 - val_loss: 1.0690 - val_mae: 0.7968 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0083 - mae: 0.7828 - val_loss: 1.0772 - val_mae: 0.8009 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0063 - mae: 0.7826 - val_loss: 1.0795 - val_mae: 0.8025 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9992 - mae: 0.7820 - val_loss: 1.0775 - val_mae: 0.8008 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 1.0080 - mae: 0.7826 - val_loss: 1.0800 - val_mae: 0.8014 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0013 - mae: 0.7812 - val_loss: 1.0871 - val_mae: 0.8053 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 1.0008 - mae: 0.7813 - val_loss: 1.0959 - val_mae: 0.8082 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0136 - mae: 0.7816 - val_loss: 1.0987 - val_mae: 0.8098 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9974 - mae: 0.7798 - val_loss: 1.0978 - val_mae: 0.8078 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0083 - mae: 0.7809 - val_loss: 1.1063 - val_mae: 0.8115 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0025 - mae: 0.7804 - val_loss: 1.1057 - val_mae: 0.8131 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.0007 - mae: 0.7802\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9943 - mae: 0.7797 - val_loss: 1.1035 - val_mae: 0.8121 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9957 - mae: 0.7791 - val_loss: 1.0942 - val_mae: 0.8087 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9967 - mae: 0.7792 - val_loss: 1.0988 - val_mae: 0.8106 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9934 - mae: 0.7783 - val_loss: 1.0945 - val_mae: 0.8087 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9994 - mae: 0.7777 - val_loss: 1.0993 - val_mae: 0.8108 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9988 - mae: 0.7777 - val_loss: 1.0987 - val_mae: 0.8104 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9943 - mae: 0.7777 - val_loss: 1.1083 - val_mae: 0.8151 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9970 - mae: 0.7773 - val_loss: 1.0996 - val_mae: 0.8104 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9890 - mae: 0.7771 - val_loss: 1.0967 - val_mae: 0.8092 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9917 - mae: 0.7765 - val_loss: 1.0951 - val_mae: 0.8087 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9910 - mae: 0.7766 - val_loss: 1.1030 - val_mae: 0.8128 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9956 - mae: 0.7765 - val_loss: 1.0947 - val_mae: 0.8104 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9954 - mae: 0.7775\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9865 - mae: 0.7765 - val_loss: 1.0932 - val_mae: 0.8092 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9898 - mae: 0.7765 - val_loss: 1.0967 - val_mae: 0.8109 - lr: 2.5000e-04\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9912 - mae: 0.7762 - val_loss: 1.0996 - val_mae: 0.8119 - lr: 2.5000e-04\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9884 - mae: 0.7759 - val_loss: 1.0978 - val_mae: 0.8109 - lr: 2.5000e-04\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9899 - mae: 0.7760 - val_loss: 1.1023 - val_mae: 0.8130 - lr: 2.5000e-04\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.9907 - mae: 0.7759 - val_loss: 1.0930 - val_mae: 0.8090 - lr: 2.5000e-04\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9940 - mae: 0.7757 - val_loss: 1.0997 - val_mae: 0.8117 - lr: 2.5000e-04\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9895 - mae: 0.7755 - val_loss: 1.0994 - val_mae: 0.8113 - lr: 2.5000e-04\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9906 - mae: 0.7751 - val_loss: 1.0950 - val_mae: 0.8098 - lr: 2.5000e-04\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9928 - mae: 0.7759 - val_loss: 1.0953 - val_mae: 0.8100 - lr: 2.5000e-04\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9877 - mae: 0.7754 - val_loss: 1.0994 - val_mae: 0.8114 - lr: 2.5000e-04\n",
            "Epoch 53/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9919 - mae: 0.7745\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9891 - mae: 0.7754 - val_loss: 1.0978 - val_mae: 0.8106 - lr: 2.5000e-04\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9952 - mae: 0.7751 - val_loss: 1.0984 - val_mae: 0.8109 - lr: 1.2500e-04\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9861 - mae: 0.7749 - val_loss: 1.1011 - val_mae: 0.8121 - lr: 1.2500e-04\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9915 - mae: 0.7754 - val_loss: 1.0981 - val_mae: 0.8107 - lr: 1.2500e-04\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9913 - mae: 0.7745 - val_loss: 1.0982 - val_mae: 0.8110 - lr: 1.2500e-04\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9893 - mae: 0.7747 - val_loss: 1.0973 - val_mae: 0.8107 - lr: 1.2500e-04\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9886 - mae: 0.7745 - val_loss: 1.0987 - val_mae: 0.8114 - lr: 1.2500e-04\n",
            "Epoch 60/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9885 - mae: 0.7745\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9908 - mae: 0.7746 - val_loss: 1.0982 - val_mae: 0.8112 - lr: 1.2500e-04\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9952 - mae: 0.7751 - val_loss: 1.0979 - val_mae: 0.8111 - lr: 6.2500e-05\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9872 - mae: 0.7737 - val_loss: 1.0980 - val_mae: 0.8111 - lr: 6.2500e-05\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9838 - mae: 0.7742 - val_loss: 1.0973 - val_mae: 0.8109 - lr: 6.2500e-05\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9870 - mae: 0.7741 - val_loss: 1.0975 - val_mae: 0.8110 - lr: 6.2500e-05\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9853 - mae: 0.7744\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9853 - mae: 0.7744 - val_loss: 1.0995 - val_mae: 0.8120 - lr: 6.2500e-05\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9879 - mae: 0.7743 - val_loss: 1.0979 - val_mae: 0.8112 - lr: 3.1250e-05\n",
            "Epoch 67/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9866 - mae: 0.7750Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9867 - mae: 0.7744 - val_loss: 1.0975 - val_mae: 0.8110 - lr: 3.1250e-05\n",
            "Epoch 00067: early stopping\n",
            "fold 2\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.2942 - mae: 0.8999 - val_loss: 1.1354 - val_mae: 0.8313 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1875 - mae: 0.8586 - val_loss: 1.0924 - val_mae: 0.8141 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1127 - mae: 0.8296 - val_loss: 1.0651 - val_mae: 0.8031 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0725 - mae: 0.8125 - val_loss: 1.0567 - val_mae: 0.7998 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0465 - mae: 0.8032 - val_loss: 1.0530 - val_mae: 0.7982 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0382 - mae: 0.7978 - val_loss: 1.0504 - val_mae: 0.7970 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0298 - mae: 0.7946 - val_loss: 1.0493 - val_mae: 0.7965 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0211 - mae: 0.7933 - val_loss: 1.0486 - val_mae: 0.7961 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0287 - mae: 0.7917 - val_loss: 1.0482 - val_mae: 0.7959 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0181 - mae: 0.7901 - val_loss: 1.0477 - val_mae: 0.7956 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0119 - mae: 0.7877 - val_loss: 1.0478 - val_mae: 0.7955 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0143 - mae: 0.7862 - val_loss: 1.0474 - val_mae: 0.7954 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0123 - mae: 0.7873 - val_loss: 1.0474 - val_mae: 0.7952 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0128 - mae: 0.7868 - val_loss: 1.0479 - val_mae: 0.7955 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0135 - mae: 0.7859 - val_loss: 1.0482 - val_mae: 0.7955 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0082 - mae: 0.7848 - val_loss: 1.0491 - val_mae: 0.7958 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0075 - mae: 0.7842 - val_loss: 1.0514 - val_mae: 0.7969 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0098 - mae: 0.7838 - val_loss: 1.0529 - val_mae: 0.7973 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0063 - mae: 0.7833 - val_loss: 1.0542 - val_mae: 0.7982 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0051 - mae: 0.7834 - val_loss: 1.0545 - val_mae: 0.7975 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0070 - mae: 0.7830 - val_loss: 1.0658 - val_mae: 0.8012 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0125 - mae: 0.7828 - val_loss: 1.0693 - val_mae: 0.8011 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0013 - mae: 0.7822 - val_loss: 1.0718 - val_mae: 0.8018 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9987 - mae: 0.7823 - val_loss: 1.0721 - val_mae: 0.8025 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0019 - mae: 0.7809 - val_loss: 1.0722 - val_mae: 0.8026 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0059 - mae: 0.7806 - val_loss: 1.0779 - val_mae: 0.8033 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9980 - mae: 0.7802 - val_loss: 1.0761 - val_mae: 0.8028 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9979 - mae: 0.7798 - val_loss: 1.0750 - val_mae: 0.8027 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9954 - mae: 0.7799 - val_loss: 1.0747 - val_mae: 0.8022 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9997 - mae: 0.7810 - val_loss: 1.0702 - val_mae: 0.8017 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 1.0015 - mae: 0.7815\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9973 - mae: 0.7803 - val_loss: 1.0762 - val_mae: 0.8027 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9939 - mae: 0.7780 - val_loss: 1.0894 - val_mae: 0.8052 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9955 - mae: 0.7786 - val_loss: 1.0866 - val_mae: 0.8056 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9953 - mae: 0.7785 - val_loss: 1.0745 - val_mae: 0.8026 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9994 - mae: 0.7777 - val_loss: 1.0835 - val_mae: 0.8049 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9978 - mae: 0.7778 - val_loss: 1.0876 - val_mae: 0.8059 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9914 - mae: 0.7772 - val_loss: 1.0814 - val_mae: 0.8043 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9948 - mae: 0.7772 - val_loss: 1.0892 - val_mae: 0.8065 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9949 - mae: 0.7770 - val_loss: 1.0926 - val_mae: 0.8075 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9922 - mae: 0.7771 - val_loss: 1.0879 - val_mae: 0.8063 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9908 - mae: 0.7768 - val_loss: 1.0757 - val_mae: 0.8034 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9939 - mae: 0.7767 - val_loss: 1.0739 - val_mae: 0.8033 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9932 - mae: 0.7774 - val_loss: 1.0803 - val_mae: 0.8046 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9948 - mae: 0.7770 - val_loss: 1.0775 - val_mae: 0.8043 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9982 - mae: 0.7788\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9938 - mae: 0.7770 - val_loss: 1.0768 - val_mae: 0.8037 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9953 - mae: 0.7765 - val_loss: 1.0820 - val_mae: 0.8055 - lr: 2.5000e-04\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9952 - mae: 0.7764 - val_loss: 1.0834 - val_mae: 0.8057 - lr: 2.5000e-04\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 1s 18ms/step - loss: 0.9929 - mae: 0.7759 - val_loss: 1.0823 - val_mae: 0.8053 - lr: 2.5000e-04\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9963 - mae: 0.7759 - val_loss: 1.0792 - val_mae: 0.8046 - lr: 2.5000e-04\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9892 - mae: 0.7763 - val_loss: 1.0833 - val_mae: 0.8057 - lr: 2.5000e-04\n",
            "Epoch 51/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9891 - mae: 0.7763\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9917 - mae: 0.7760 - val_loss: 1.0801 - val_mae: 0.8051 - lr: 2.5000e-04\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9894 - mae: 0.7752 - val_loss: 1.0807 - val_mae: 0.8052 - lr: 1.2500e-04\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9879 - mae: 0.7753 - val_loss: 1.0788 - val_mae: 0.8045 - lr: 1.2500e-04\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9898 - mae: 0.7748 - val_loss: 1.0815 - val_mae: 0.8054 - lr: 1.2500e-04\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9880 - mae: 0.7757 - val_loss: 1.0788 - val_mae: 0.8046 - lr: 1.2500e-04\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9887 - mae: 0.7749 - val_loss: 1.0809 - val_mae: 0.8051 - lr: 1.2500e-04\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9839 - mae: 0.7746 - val_loss: 1.0801 - val_mae: 0.8048 - lr: 1.2500e-04\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9889 - mae: 0.7746 - val_loss: 1.0804 - val_mae: 0.8049 - lr: 1.2500e-04\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9915 - mae: 0.7752 - val_loss: 1.0808 - val_mae: 0.8048 - lr: 1.2500e-04\n",
            "Epoch 60/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9900 - mae: 0.7752\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9875 - mae: 0.7753 - val_loss: 1.0795 - val_mae: 0.8044 - lr: 1.2500e-04\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9838 - mae: 0.7745 - val_loss: 1.0805 - val_mae: 0.8047 - lr: 6.2500e-05\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9859 - mae: 0.7746Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9859 - mae: 0.7746 - val_loss: 1.0796 - val_mae: 0.8044 - lr: 6.2500e-05\n",
            "Epoch 00062: early stopping\n",
            "fold 3\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.2989 - mae: 0.9001 - val_loss: 1.2382 - val_mae: 0.8703 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.1795 - mae: 0.8573 - val_loss: 1.1349 - val_mae: 0.8342 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.1119 - mae: 0.8316 - val_loss: 1.0885 - val_mae: 0.8189 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0782 - mae: 0.8147 - val_loss: 1.0677 - val_mae: 0.8130 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.0505 - mae: 0.8039 - val_loss: 1.0606 - val_mae: 0.8116 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0395 - mae: 0.7984 - val_loss: 1.0575 - val_mae: 0.8115 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0290 - mae: 0.7942 - val_loss: 1.0564 - val_mae: 0.8116 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0199 - mae: 0.7907 - val_loss: 1.0560 - val_mae: 0.8117 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0169 - mae: 0.7901 - val_loss: 1.0558 - val_mae: 0.8120 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0172 - mae: 0.7884 - val_loss: 1.0558 - val_mae: 0.8120 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.0094 - mae: 0.7873 - val_loss: 1.0552 - val_mae: 0.8119 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0082 - mae: 0.7854 - val_loss: 1.0546 - val_mae: 0.8116 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.0080 - mae: 0.7853 - val_loss: 1.0543 - val_mae: 0.8116 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0024 - mae: 0.7843 - val_loss: 1.0537 - val_mae: 0.8112 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0059 - mae: 0.7850 - val_loss: 1.0530 - val_mae: 0.8109 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 1.0069 - mae: 0.7839 - val_loss: 1.0521 - val_mae: 0.8105 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0009 - mae: 0.7839 - val_loss: 1.0520 - val_mae: 0.8102 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9992 - mae: 0.7836 - val_loss: 1.0525 - val_mae: 0.8104 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0015 - mae: 0.7829 - val_loss: 1.0553 - val_mae: 0.8112 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0001 - mae: 0.7822 - val_loss: 1.0582 - val_mae: 0.8131 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0008 - mae: 0.7824 - val_loss: 1.0600 - val_mae: 0.8134 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0102 - mae: 0.7816 - val_loss: 1.0668 - val_mae: 0.8159 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9976 - mae: 0.7806 - val_loss: 1.0626 - val_mae: 0.8135 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9992 - mae: 0.7812 - val_loss: 1.0660 - val_mae: 0.8137 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.9944 - mae: 0.7805 - val_loss: 1.0725 - val_mae: 0.8160 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9983 - mae: 0.7803 - val_loss: 1.0751 - val_mae: 0.8149 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.9921 - mae: 0.7799 - val_loss: 1.0661 - val_mae: 0.8132 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9961 - mae: 0.7798 - val_loss: 1.0787 - val_mae: 0.8161 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9978 - mae: 0.7798 - val_loss: 1.0767 - val_mae: 0.8164 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9993 - mae: 0.7799 - val_loss: 1.0689 - val_mae: 0.8134 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9956 - mae: 0.7785 - val_loss: 1.0784 - val_mae: 0.8164 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9943 - mae: 0.7787 - val_loss: 1.0707 - val_mae: 0.8144 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9945 - mae: 0.7797 - val_loss: 1.0861 - val_mae: 0.8167 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9954 - mae: 0.7796\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9954 - mae: 0.7796 - val_loss: 1.0906 - val_mae: 0.8196 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9896 - mae: 0.7770 - val_loss: 1.0839 - val_mae: 0.8180 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9899 - mae: 0.7769 - val_loss: 1.0942 - val_mae: 0.8213 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9915 - mae: 0.7769 - val_loss: 1.0863 - val_mae: 0.8183 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9901 - mae: 0.7767 - val_loss: 1.0903 - val_mae: 0.8194 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9916 - mae: 0.7762 - val_loss: 1.0773 - val_mae: 0.8157 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9892 - mae: 0.7760 - val_loss: 1.0813 - val_mae: 0.8168 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9914 - mae: 0.7757 - val_loss: 1.0928 - val_mae: 0.8202 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9937 - mae: 0.7763 - val_loss: 1.0737 - val_mae: 0.8145 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9841 - mae: 0.7762 - val_loss: 1.0778 - val_mae: 0.8158 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 0.9884 - mae: 0.7755\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9909 - mae: 0.7763 - val_loss: 1.0799 - val_mae: 0.8166 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9889 - mae: 0.7755 - val_loss: 1.0887 - val_mae: 0.8191 - lr: 2.5000e-04\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9889 - mae: 0.7755 - val_loss: 1.0829 - val_mae: 0.8173 - lr: 2.5000e-04\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9910 - mae: 0.7752 - val_loss: 1.0809 - val_mae: 0.8167 - lr: 2.5000e-04\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9871 - mae: 0.7750 - val_loss: 1.0899 - val_mae: 0.8194 - lr: 2.5000e-04\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9854 - mae: 0.7752 - val_loss: 1.0809 - val_mae: 0.8166 - lr: 2.5000e-04\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9881 - mae: 0.7745 - val_loss: 1.0876 - val_mae: 0.8185 - lr: 2.5000e-04\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9863 - mae: 0.7747 - val_loss: 1.0852 - val_mae: 0.8180 - lr: 2.5000e-04\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.9849 - mae: 0.7748 - val_loss: 1.0836 - val_mae: 0.8171 - lr: 2.5000e-04\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9841 - mae: 0.7748\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9841 - mae: 0.7748 - val_loss: 1.0875 - val_mae: 0.8186 - lr: 2.5000e-04\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9825 - mae: 0.7741 - val_loss: 1.0834 - val_mae: 0.8175 - lr: 1.2500e-04\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9837 - mae: 0.7742 - val_loss: 1.0848 - val_mae: 0.8180 - lr: 1.2500e-04\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9822 - mae: 0.7738 - val_loss: 1.0827 - val_mae: 0.8174 - lr: 1.2500e-04\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9837 - mae: 0.7738 - val_loss: 1.0875 - val_mae: 0.8185 - lr: 1.2500e-04\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9825 - mae: 0.7742 - val_loss: 1.0845 - val_mae: 0.8176 - lr: 1.2500e-04\n",
            "Epoch 59/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 0.9881 - mae: 0.7761\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9839 - mae: 0.7740 - val_loss: 1.0848 - val_mae: 0.8176 - lr: 1.2500e-04\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9844 - mae: 0.7736 - val_loss: 1.0853 - val_mae: 0.8178 - lr: 6.2500e-05\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9881 - mae: 0.7738 - val_loss: 1.0844 - val_mae: 0.8176 - lr: 6.2500e-05\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9840 - mae: 0.7734 - val_loss: 1.0850 - val_mae: 0.8177 - lr: 6.2500e-05\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9829 - mae: 0.7739 - val_loss: 1.0853 - val_mae: 0.8178 - lr: 6.2500e-05\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9827 - mae: 0.7740 - val_loss: 1.0849 - val_mae: 0.8177 - lr: 6.2500e-05\n",
            "Epoch 65/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9867 - mae: 0.7737\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9840 - mae: 0.7740 - val_loss: 1.0847 - val_mae: 0.8177 - lr: 6.2500e-05\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9853 - mae: 0.7733 - val_loss: 1.0850 - val_mae: 0.8178 - lr: 3.1250e-05\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9870 - mae: 0.7738 - val_loss: 1.0855 - val_mae: 0.8179 - lr: 3.1250e-05\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9878 - mae: 0.7734 - val_loss: 1.0850 - val_mae: 0.8178 - lr: 3.1250e-05\n",
            "Epoch 69/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 0.9800 - mae: 0.7718\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9915 - mae: 0.7735 - val_loss: 1.0857 - val_mae: 0.8180 - lr: 3.1250e-05\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9865 - mae: 0.7734 - val_loss: 1.0855 - val_mae: 0.8179 - lr: 1.5625e-05\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9799 - mae: 0.7730 - val_loss: 1.0853 - val_mae: 0.8179 - lr: 1.5625e-05\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9799 - mae: 0.7731 - val_loss: 1.0854 - val_mae: 0.8179 - lr: 1.5625e-05\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9806 - mae: 0.7730 - val_loss: 1.0855 - val_mae: 0.8179 - lr: 1.5625e-05\n",
            "Epoch 74/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9845 - mae: 0.7732\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9816 - mae: 0.7732 - val_loss: 1.0856 - val_mae: 0.8180 - lr: 1.5625e-05\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9860 - mae: 0.7731 - val_loss: 1.0856 - val_mae: 0.8180 - lr: 7.8125e-06\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9818 - mae: 0.7733Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9818 - mae: 0.7733 - val_loss: 1.0857 - val_mae: 0.8180 - lr: 7.8125e-06\n",
            "Epoch 00076: early stopping\n",
            "fold 4\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.3088 - mae: 0.9018 - val_loss: 1.1197 - val_mae: 0.8431 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.1883 - mae: 0.8574 - val_loss: 1.0670 - val_mae: 0.8241 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1145 - mae: 0.8297 - val_loss: 1.0338 - val_mae: 0.8131 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0714 - mae: 0.8137 - val_loss: 1.0187 - val_mae: 0.8087 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0529 - mae: 0.8036 - val_loss: 1.0103 - val_mae: 0.8066 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0366 - mae: 0.7988 - val_loss: 1.0064 - val_mae: 0.8061 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0307 - mae: 0.7939 - val_loss: 1.0054 - val_mae: 0.8060 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0265 - mae: 0.7926 - val_loss: 1.0046 - val_mae: 0.8060 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0244 - mae: 0.7908 - val_loss: 1.0046 - val_mae: 0.8061 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0219 - mae: 0.7902 - val_loss: 1.0043 - val_mae: 0.8061 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0160 - mae: 0.7878 - val_loss: 1.0043 - val_mae: 0.8060 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0120 - mae: 0.7863 - val_loss: 1.0043 - val_mae: 0.8060 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0119 - mae: 0.7858 - val_loss: 1.0041 - val_mae: 0.8058 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0064 - mae: 0.7855 - val_loss: 1.0048 - val_mae: 0.8060 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0117 - mae: 0.7857 - val_loss: 1.0047 - val_mae: 0.8055 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0094 - mae: 0.7841 - val_loss: 1.0051 - val_mae: 0.8055 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0110 - mae: 0.7843 - val_loss: 1.0050 - val_mae: 0.8055 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0031 - mae: 0.7840 - val_loss: 1.0102 - val_mae: 0.8072 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0059 - mae: 0.7834 - val_loss: 1.0090 - val_mae: 0.8068 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0045 - mae: 0.7832 - val_loss: 1.0110 - val_mae: 0.8082 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0049 - mae: 0.7833 - val_loss: 1.0132 - val_mae: 0.8092 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0052 - mae: 0.7814 - val_loss: 1.0156 - val_mae: 0.8114 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0054 - mae: 0.7819 - val_loss: 1.0238 - val_mae: 0.8141 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9997 - mae: 0.7809 - val_loss: 1.0174 - val_mae: 0.8117 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9981 - mae: 0.7810 - val_loss: 1.0223 - val_mae: 0.8118 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9965 - mae: 0.7802 - val_loss: 1.0213 - val_mae: 0.8123 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0010 - mae: 0.7807 - val_loss: 1.0181 - val_mae: 0.8112 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0010 - mae: 0.7806 - val_loss: 1.0209 - val_mae: 0.8115 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0012 - mae: 0.7796 - val_loss: 1.0279 - val_mae: 0.8144 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0007 - mae: 0.7797 - val_loss: 1.0220 - val_mae: 0.8125 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9951 - mae: 0.7788 - val_loss: 1.0275 - val_mae: 0.8143 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0068 - mae: 0.7793 - val_loss: 1.0270 - val_mae: 0.8142 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9994 - mae: 0.7794 - val_loss: 1.0261 - val_mae: 0.8139 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 1.0031 - mae: 0.7802\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9974 - mae: 0.7792 - val_loss: 1.0260 - val_mae: 0.8139 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9940 - mae: 0.7776 - val_loss: 1.0282 - val_mae: 0.8155 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9916 - mae: 0.7768 - val_loss: 1.0210 - val_mae: 0.8128 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9923 - mae: 0.7772 - val_loss: 1.0334 - val_mae: 0.8172 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9932 - mae: 0.7767 - val_loss: 1.0287 - val_mae: 0.8154 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9917 - mae: 0.7760 - val_loss: 1.0296 - val_mae: 0.8157 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9913 - mae: 0.7758 - val_loss: 1.0239 - val_mae: 0.8133 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9922 - mae: 0.7759 - val_loss: 1.0221 - val_mae: 0.8125 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9925 - mae: 0.7765 - val_loss: 1.0229 - val_mae: 0.8133 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9915 - mae: 0.7775\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9944 - mae: 0.7769 - val_loss: 1.0300 - val_mae: 0.8161 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9867 - mae: 0.7755 - val_loss: 1.0243 - val_mae: 0.8139 - lr: 2.5000e-04\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9880 - mae: 0.7757 - val_loss: 1.0251 - val_mae: 0.8143 - lr: 2.5000e-04\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.9884 - mae: 0.7749 - val_loss: 1.0293 - val_mae: 0.8160 - lr: 2.5000e-04\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9929 - mae: 0.7756 - val_loss: 1.0223 - val_mae: 0.8135 - lr: 2.5000e-04\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9897 - mae: 0.7754 - val_loss: 1.0312 - val_mae: 0.8168 - lr: 2.5000e-04\n",
            "Epoch 49/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 0.9936 - mae: 0.7762\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9881 - mae: 0.7754 - val_loss: 1.0246 - val_mae: 0.8143 - lr: 2.5000e-04\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9920 - mae: 0.7747 - val_loss: 1.0286 - val_mae: 0.8157 - lr: 1.2500e-04\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9890 - mae: 0.7745 - val_loss: 1.0271 - val_mae: 0.8150 - lr: 1.2500e-04\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9922 - mae: 0.7750 - val_loss: 1.0256 - val_mae: 0.8146 - lr: 1.2500e-04\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9895 - mae: 0.7747 - val_loss: 1.0282 - val_mae: 0.8157 - lr: 1.2500e-04\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9876 - mae: 0.7742 - val_loss: 1.0273 - val_mae: 0.8154 - lr: 1.2500e-04\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9851 - mae: 0.7736 - val_loss: 1.0279 - val_mae: 0.8156 - lr: 1.2500e-04\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9909 - mae: 0.7738 - val_loss: 1.0258 - val_mae: 0.8148 - lr: 1.2500e-04\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9924 - mae: 0.7746 - val_loss: 1.0246 - val_mae: 0.8143 - lr: 1.2500e-04\n",
            "Epoch 58/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9899 - mae: 0.7745\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9876 - mae: 0.7743 - val_loss: 1.0265 - val_mae: 0.8150 - lr: 1.2500e-04\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9850 - mae: 0.7741 - val_loss: 1.0263 - val_mae: 0.8149 - lr: 6.2500e-05\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9867 - mae: 0.7745Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.9867 - mae: 0.7745 - val_loss: 1.0255 - val_mae: 0.8146 - lr: 6.2500e-05\n",
            "Epoch 00060: early stopping\n",
            "fold 5\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.2994 - mae: 0.9007 - val_loss: 1.1774 - val_mae: 0.8640 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.1897 - mae: 0.8598 - val_loss: 1.1343 - val_mae: 0.8465 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.1199 - mae: 0.8312 - val_loss: 1.0571 - val_mae: 0.8139 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0735 - mae: 0.8135 - val_loss: 1.0195 - val_mae: 0.7970 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0593 - mae: 0.8036 - val_loss: 1.0100 - val_mae: 0.7921 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0491 - mae: 0.7995 - val_loss: 1.0075 - val_mae: 0.7906 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0314 - mae: 0.7959 - val_loss: 1.0066 - val_mae: 0.7899 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0306 - mae: 0.7921 - val_loss: 1.0058 - val_mae: 0.7894 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0268 - mae: 0.7913 - val_loss: 1.0057 - val_mae: 0.7892 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0184 - mae: 0.7908 - val_loss: 1.0056 - val_mae: 0.7891 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0131 - mae: 0.7876 - val_loss: 1.0056 - val_mae: 0.7890 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0198 - mae: 0.7874 - val_loss: 1.0052 - val_mae: 0.7889 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0095 - mae: 0.7859 - val_loss: 1.0056 - val_mae: 0.7891 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0150 - mae: 0.7865 - val_loss: 1.0059 - val_mae: 0.7893 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0093 - mae: 0.7850 - val_loss: 1.0076 - val_mae: 0.7897 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0114 - mae: 0.7847 - val_loss: 1.0087 - val_mae: 0.7905 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0125 - mae: 0.7850 - val_loss: 1.0107 - val_mae: 0.7913 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0127 - mae: 0.7855 - val_loss: 1.0150 - val_mae: 0.7931 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0104 - mae: 0.7843 - val_loss: 1.0176 - val_mae: 0.7953 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0102 - mae: 0.7842 - val_loss: 1.0212 - val_mae: 0.7973 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0100 - mae: 0.7839 - val_loss: 1.0290 - val_mae: 0.8008 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0057 - mae: 0.7829 - val_loss: 1.0300 - val_mae: 0.8016 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0057 - mae: 0.7823 - val_loss: 1.0292 - val_mae: 0.8016 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0027 - mae: 0.7827 - val_loss: 1.0284 - val_mae: 0.8018 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0032 - mae: 0.7825 - val_loss: 1.0364 - val_mae: 0.8045 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0032 - mae: 0.7806 - val_loss: 1.0337 - val_mae: 0.8025 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0055 - mae: 0.7800 - val_loss: 1.0413 - val_mae: 0.8062 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0021 - mae: 0.7816 - val_loss: 1.0431 - val_mae: 0.8077 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9970 - mae: 0.7804 - val_loss: 1.0519 - val_mae: 0.8119 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.0004 - mae: 0.7807\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0004 - mae: 0.7807 - val_loss: 1.0429 - val_mae: 0.8082 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0019 - mae: 0.7793 - val_loss: 1.0328 - val_mae: 0.8035 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9978 - mae: 0.7790 - val_loss: 1.0389 - val_mae: 0.8062 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0013 - mae: 0.7792 - val_loss: 1.0373 - val_mae: 0.8053 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0055 - mae: 0.7791 - val_loss: 1.0392 - val_mae: 0.8065 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9957 - mae: 0.7779 - val_loss: 1.0410 - val_mae: 0.8072 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9944 - mae: 0.7780 - val_loss: 1.0380 - val_mae: 0.8059 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9959 - mae: 0.7784 - val_loss: 1.0407 - val_mae: 0.8072 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9887 - mae: 0.7747\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9984 - mae: 0.7779 - val_loss: 1.0357 - val_mae: 0.8048 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9947 - mae: 0.7767 - val_loss: 1.0362 - val_mae: 0.8050 - lr: 2.5000e-04\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9952 - mae: 0.7773 - val_loss: 1.0385 - val_mae: 0.8060 - lr: 2.5000e-04\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9907 - mae: 0.7767 - val_loss: 1.0384 - val_mae: 0.8060 - lr: 2.5000e-04\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9924 - mae: 0.7769\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9924 - mae: 0.7769 - val_loss: 1.0388 - val_mae: 0.8063 - lr: 2.5000e-04\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9934 - mae: 0.7761 - val_loss: 1.0402 - val_mae: 0.8069 - lr: 1.2500e-04\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9915 - mae: 0.7760 - val_loss: 1.0405 - val_mae: 0.8070 - lr: 1.2500e-04\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9924 - mae: 0.7768 - val_loss: 1.0394 - val_mae: 0.8065 - lr: 1.2500e-04\n",
            "Epoch 46/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9940 - mae: 0.7765\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9959 - mae: 0.7767 - val_loss: 1.0394 - val_mae: 0.8066 - lr: 1.2500e-04\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9992 - mae: 0.7761 - val_loss: 1.0394 - val_mae: 0.8066 - lr: 6.2500e-05\n",
            "Epoch 48/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 1.0051 - mae: 0.7794Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9936 - mae: 0.7765 - val_loss: 1.0393 - val_mae: 0.8065 - lr: 6.2500e-05\n",
            "Epoch 00048: early stopping\n",
            "fold 6\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.2940 - mae: 0.8962 - val_loss: 1.1916 - val_mae: 0.8918 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1875 - mae: 0.8587 - val_loss: 1.1036 - val_mae: 0.8577 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.1126 - mae: 0.8277 - val_loss: 1.0401 - val_mae: 0.8314 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0713 - mae: 0.8130 - val_loss: 1.0154 - val_mae: 0.8205 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0482 - mae: 0.8010 - val_loss: 1.0082 - val_mae: 0.8174 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0317 - mae: 0.7965 - val_loss: 1.0042 - val_mae: 0.8156 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0206 - mae: 0.7915 - val_loss: 1.0026 - val_mae: 0.8148 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0166 - mae: 0.7896 - val_loss: 1.0019 - val_mae: 0.8145 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0137 - mae: 0.7880 - val_loss: 1.0013 - val_mae: 0.8142 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0124 - mae: 0.7867 - val_loss: 1.0011 - val_mae: 0.8141 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0165 - mae: 0.7854 - val_loss: 1.0007 - val_mae: 0.8139 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0063 - mae: 0.7837 - val_loss: 1.0002 - val_mae: 0.8137 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0042 - mae: 0.7846 - val_loss: 1.0000 - val_mae: 0.8135 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0041 - mae: 0.7822 - val_loss: 1.0000 - val_mae: 0.8135 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0008 - mae: 0.7825 - val_loss: 1.0020 - val_mae: 0.8140 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0025 - mae: 0.7832 - val_loss: 1.0017 - val_mae: 0.8144 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9988 - mae: 0.7811\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0101 - mae: 0.7821 - val_loss: 1.0006 - val_mae: 0.8138 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9965 - mae: 0.7799 - val_loss: 1.0093 - val_mae: 0.8171 - lr: 5.0000e-04\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9973 - mae: 0.7794 - val_loss: 1.0137 - val_mae: 0.8187 - lr: 5.0000e-04\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9981 - mae: 0.7794 - val_loss: 1.0235 - val_mae: 0.8218 - lr: 5.0000e-04\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0024 - mae: 0.7799 - val_loss: 1.0295 - val_mae: 0.8238 - lr: 5.0000e-04\n",
            "Epoch 22/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9966 - mae: 0.7794\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9974 - mae: 0.7794 - val_loss: 1.0314 - val_mae: 0.8241 - lr: 5.0000e-04\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9902 - mae: 0.7784 - val_loss: 1.0349 - val_mae: 0.8251 - lr: 2.5000e-04\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9979 - mae: 0.7785 - val_loss: 1.0407 - val_mae: 0.8270 - lr: 2.5000e-04\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9978 - mae: 0.7777 - val_loss: 1.0418 - val_mae: 0.8274 - lr: 2.5000e-04\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9957 - mae: 0.7782 - val_loss: 1.0394 - val_mae: 0.8267 - lr: 2.5000e-04\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9969 - mae: 0.7784 - val_loss: 1.0415 - val_mae: 0.8275 - lr: 2.5000e-04\n",
            "Epoch 28/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9848 - mae: 0.7758\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9974 - mae: 0.7781 - val_loss: 1.0432 - val_mae: 0.8278 - lr: 2.5000e-04\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9927 - mae: 0.7772 - val_loss: 1.0471 - val_mae: 0.8290 - lr: 1.2500e-04\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9981 - mae: 0.7770 - val_loss: 1.0488 - val_mae: 0.8296 - lr: 1.2500e-04\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9902 - mae: 0.7775 - val_loss: 1.0474 - val_mae: 0.8292 - lr: 1.2500e-04\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9990 - mae: 0.7775 - val_loss: 1.0492 - val_mae: 0.8299 - lr: 1.2500e-04\n",
            "Epoch 33/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 0.9859 - mae: 0.7764\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9954 - mae: 0.7770 - val_loss: 1.0507 - val_mae: 0.8302 - lr: 1.2500e-04\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9949 - mae: 0.7771 - val_loss: 1.0499 - val_mae: 0.8300 - lr: 6.2500e-05\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9988 - mae: 0.7767 - val_loss: 1.0507 - val_mae: 0.8303 - lr: 6.2500e-05\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9964 - mae: 0.7769 - val_loss: 1.0503 - val_mae: 0.8301 - lr: 6.2500e-05\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9886 - mae: 0.7776 - val_loss: 1.0510 - val_mae: 0.8303 - lr: 6.2500e-05\n",
            "Epoch 38/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 0.9891 - mae: 0.7751\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9893 - mae: 0.7770 - val_loss: 1.0495 - val_mae: 0.8299 - lr: 6.2500e-05\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9952 - mae: 0.7765 - val_loss: 1.0492 - val_mae: 0.8298 - lr: 3.1250e-05\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9938 - mae: 0.7772 - val_loss: 1.0510 - val_mae: 0.8303 - lr: 3.1250e-05\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9944 - mae: 0.7760 - val_loss: 1.0531 - val_mae: 0.8310 - lr: 3.1250e-05\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9911 - mae: 0.7769 - val_loss: 1.0514 - val_mae: 0.8304 - lr: 3.1250e-05\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9935 - mae: 0.7767 - val_loss: 1.0503 - val_mae: 0.8300 - lr: 3.1250e-05\n",
            "Epoch 44/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 0.9900 - mae: 0.7757\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9891 - mae: 0.7761 - val_loss: 1.0518 - val_mae: 0.8305 - lr: 3.1250e-05\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9949 - mae: 0.7758 - val_loss: 1.0520 - val_mae: 0.8305 - lr: 1.5625e-05\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9886 - mae: 0.7769 - val_loss: 1.0516 - val_mae: 0.8304 - lr: 1.5625e-05\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9934 - mae: 0.7766 - val_loss: 1.0510 - val_mae: 0.8302 - lr: 1.5625e-05\n",
            "Epoch 48/100\n",
            "26/29 [=========================>....] - ETA: 0s - loss: 0.9917 - mae: 0.7774\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9981 - mae: 0.7760 - val_loss: 1.0510 - val_mae: 0.8302 - lr: 1.5625e-05\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9896 - mae: 0.7764 - val_loss: 1.0511 - val_mae: 0.8302 - lr: 7.8125e-06\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9913 - mae: 0.7762Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.9913 - mae: 0.7762 - val_loss: 1.0512 - val_mae: 0.8303 - lr: 7.8125e-06\n",
            "Epoch 00050: early stopping\n",
            "fold 7\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.2938 - mae: 0.8990 - val_loss: 1.3379 - val_mae: 0.8908 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1812 - mae: 0.8595 - val_loss: 1.2091 - val_mae: 0.8434 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1144 - mae: 0.8310 - val_loss: 1.1353 - val_mae: 0.8166 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0712 - mae: 0.8125 - val_loss: 1.1042 - val_mae: 0.8065 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0489 - mae: 0.8038 - val_loss: 1.0931 - val_mae: 0.8037 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0270 - mae: 0.7981 - val_loss: 1.0884 - val_mae: 0.8030 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0274 - mae: 0.7947 - val_loss: 1.0868 - val_mae: 0.8029 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0199 - mae: 0.7919 - val_loss: 1.0862 - val_mae: 0.8030 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0164 - mae: 0.7905 - val_loss: 1.0857 - val_mae: 0.8030 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0115 - mae: 0.7890 - val_loss: 1.0857 - val_mae: 0.8031 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0096 - mae: 0.7866 - val_loss: 1.0854 - val_mae: 0.8031 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0106 - mae: 0.7868 - val_loss: 1.0845 - val_mae: 0.8029 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0052 - mae: 0.7860 - val_loss: 1.0838 - val_mae: 0.8030 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0100 - mae: 0.7864 - val_loss: 1.0831 - val_mae: 0.8031 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0000 - mae: 0.7838 - val_loss: 1.0831 - val_mae: 0.8031 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0048 - mae: 0.7848 - val_loss: 1.0845 - val_mae: 0.8042 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0004 - mae: 0.7837 - val_loss: 1.0850 - val_mae: 0.8047 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9987 - mae: 0.7831 - val_loss: 1.0846 - val_mae: 0.8045 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 1.0035 - mae: 0.7834 - val_loss: 1.0881 - val_mae: 0.8065 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0011 - mae: 0.7821 - val_loss: 1.0900 - val_mae: 0.8070 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9983 - mae: 0.7832 - val_loss: 1.0929 - val_mae: 0.8077 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9959 - mae: 0.7816 - val_loss: 1.0962 - val_mae: 0.8088 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9990 - mae: 0.7807 - val_loss: 1.0939 - val_mae: 0.8083 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9954 - mae: 0.7812 - val_loss: 1.1008 - val_mae: 0.8110 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9952 - mae: 0.7815 - val_loss: 1.0970 - val_mae: 0.8097 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9968 - mae: 0.7816\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9981 - mae: 0.7810 - val_loss: 1.0971 - val_mae: 0.8100 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9955 - mae: 0.7801 - val_loss: 1.1075 - val_mae: 0.8134 - lr: 5.0000e-04\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9934 - mae: 0.7797 - val_loss: 1.1101 - val_mae: 0.8138 - lr: 5.0000e-04\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9913 - mae: 0.7795 - val_loss: 1.1116 - val_mae: 0.8139 - lr: 5.0000e-04\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9933 - mae: 0.7794 - val_loss: 1.1102 - val_mae: 0.8137 - lr: 5.0000e-04\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9917 - mae: 0.7784 - val_loss: 1.1112 - val_mae: 0.8130 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9895 - mae: 0.7782 - val_loss: 1.1141 - val_mae: 0.8139 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9910 - mae: 0.7783 - val_loss: 1.1116 - val_mae: 0.8129 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9881 - mae: 0.7781 - val_loss: 1.1102 - val_mae: 0.8128 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9982 - mae: 0.7778 - val_loss: 1.1101 - val_mae: 0.8129 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9949 - mae: 0.7788 - val_loss: 1.1150 - val_mae: 0.8140 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9894 - mae: 0.7782 - val_loss: 1.1113 - val_mae: 0.8130 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9911 - mae: 0.7779\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9911 - mae: 0.7779 - val_loss: 1.1109 - val_mae: 0.8124 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9932 - mae: 0.7773 - val_loss: 1.1210 - val_mae: 0.8157 - lr: 2.5000e-04\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9873 - mae: 0.7763 - val_loss: 1.1200 - val_mae: 0.8150 - lr: 2.5000e-04\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9932 - mae: 0.7775 - val_loss: 1.1141 - val_mae: 0.8133 - lr: 2.5000e-04\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9867 - mae: 0.7763 - val_loss: 1.1189 - val_mae: 0.8147 - lr: 2.5000e-04\n",
            "Epoch 43/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9887 - mae: 0.7774\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9905 - mae: 0.7774 - val_loss: 1.1174 - val_mae: 0.8139 - lr: 2.5000e-04\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9891 - mae: 0.7753 - val_loss: 1.1197 - val_mae: 0.8146 - lr: 1.2500e-04\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9852 - mae: 0.7769 - val_loss: 1.1190 - val_mae: 0.8143 - lr: 1.2500e-04\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9890 - mae: 0.7765 - val_loss: 1.1210 - val_mae: 0.8148 - lr: 1.2500e-04\n",
            "Epoch 47/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9858 - mae: 0.7750\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9868 - mae: 0.7752 - val_loss: 1.1189 - val_mae: 0.8143 - lr: 1.2500e-04\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9910 - mae: 0.7757 - val_loss: 1.1198 - val_mae: 0.8145 - lr: 6.2500e-05\n",
            "Epoch 49/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9882 - mae: 0.7761Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9910 - mae: 0.7762 - val_loss: 1.1178 - val_mae: 0.8139 - lr: 6.2500e-05\n",
            "Epoch 00049: early stopping\n",
            "fold 8\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 15ms/step - loss: 1.2962 - mae: 0.9008 - val_loss: 1.3608 - val_mae: 0.9214 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1739 - mae: 0.8553 - val_loss: 1.2319 - val_mae: 0.8738 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1117 - mae: 0.8290 - val_loss: 1.1435 - val_mae: 0.8416 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0755 - mae: 0.8117 - val_loss: 1.1026 - val_mae: 0.8276 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0397 - mae: 0.8012 - val_loss: 1.0817 - val_mae: 0.8210 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0238 - mae: 0.7953 - val_loss: 1.0763 - val_mae: 0.8195 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0209 - mae: 0.7932 - val_loss: 1.0728 - val_mae: 0.8187 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0226 - mae: 0.7924 - val_loss: 1.0721 - val_mae: 0.8186 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0155 - mae: 0.7877 - val_loss: 1.0713 - val_mae: 0.8185 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0087 - mae: 0.7868 - val_loss: 1.0706 - val_mae: 0.8184 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0073 - mae: 0.7852 - val_loss: 1.0703 - val_mae: 0.8182 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0022 - mae: 0.7841 - val_loss: 1.0701 - val_mae: 0.8184 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0048 - mae: 0.7841 - val_loss: 1.0702 - val_mae: 0.8183 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 1.0051 - mae: 0.7846 - val_loss: 1.0703 - val_mae: 0.8186 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9991 - mae: 0.7822 - val_loss: 1.0706 - val_mae: 0.8187 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0051 - mae: 0.7834 - val_loss: 1.0714 - val_mae: 0.8184 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9977 - mae: 0.7818 - val_loss: 1.0731 - val_mae: 0.8185 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9952 - mae: 0.7811 - val_loss: 1.0733 - val_mae: 0.8185 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0059 - mae: 0.7821 - val_loss: 1.0769 - val_mae: 0.8190 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9956 - mae: 0.7815 - val_loss: 1.0800 - val_mae: 0.8195 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9959 - mae: 0.7799 - val_loss: 1.0797 - val_mae: 0.8203 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9953 - mae: 0.7805 - val_loss: 1.0819 - val_mae: 0.8200 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9987 - mae: 0.7798 - val_loss: 1.0876 - val_mae: 0.8224 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9964 - mae: 0.7800 - val_loss: 1.0848 - val_mae: 0.8215 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9916 - mae: 0.7794 - val_loss: 1.0846 - val_mae: 0.8219 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9979 - mae: 0.7791 - val_loss: 1.0989 - val_mae: 0.8265 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9899 - mae: 0.7782 - val_loss: 1.1071 - val_mae: 0.8272 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9938 - mae: 0.7782 - val_loss: 1.0957 - val_mae: 0.8236 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9929 - mae: 0.7780 - val_loss: 1.0951 - val_mae: 0.8237 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9957 - mae: 0.7775 - val_loss: 1.1052 - val_mae: 0.8264 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9888 - mae: 0.7780 - val_loss: 1.1107 - val_mae: 0.8280 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9885 - mae: 0.7778 - val_loss: 1.1075 - val_mae: 0.8279 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9896 - mae: 0.7765 - val_loss: 1.1028 - val_mae: 0.8262 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9885 - mae: 0.7766 - val_loss: 1.1046 - val_mae: 0.8269 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9897 - mae: 0.7768 - val_loss: 1.1021 - val_mae: 0.8270 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9891 - mae: 0.7761 - val_loss: 1.1046 - val_mae: 0.8268 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9967 - mae: 0.7758 - val_loss: 1.1038 - val_mae: 0.8262 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9838 - mae: 0.7758 - val_loss: 1.0976 - val_mae: 0.8249 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9881 - mae: 0.7756 - val_loss: 1.1105 - val_mae: 0.8271 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9912 - mae: 0.7757 - val_loss: 1.1031 - val_mae: 0.8255 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9845 - mae: 0.7749 - val_loss: 1.1045 - val_mae: 0.8265 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9848 - mae: 0.7746 - val_loss: 1.1044 - val_mae: 0.8260 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9872 - mae: 0.7745 - val_loss: 1.1051 - val_mae: 0.8258 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9935 - mae: 0.7749 - val_loss: 1.1202 - val_mae: 0.8302 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "24/29 [=======================>......] - ETA: 0s - loss: 0.9810 - mae: 0.7752\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9863 - mae: 0.7745 - val_loss: 1.0988 - val_mae: 0.8242 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9809 - mae: 0.7727 - val_loss: 1.1058 - val_mae: 0.8265 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9803 - mae: 0.7729 - val_loss: 1.1059 - val_mae: 0.8262 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9813 - mae: 0.7725 - val_loss: 1.1056 - val_mae: 0.8264 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9823 - mae: 0.7728 - val_loss: 1.1067 - val_mae: 0.8268 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9826 - mae: 0.7720 - val_loss: 1.1046 - val_mae: 0.8259 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9772 - mae: 0.7726 - val_loss: 1.1007 - val_mae: 0.8255 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9812 - mae: 0.7719 - val_loss: 1.1040 - val_mae: 0.8262 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9779 - mae: 0.7722\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9779 - mae: 0.7722 - val_loss: 1.1059 - val_mae: 0.8268 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9831 - mae: 0.7721 - val_loss: 1.1080 - val_mae: 0.8274 - lr: 2.5000e-04\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9797 - mae: 0.7716 - val_loss: 1.1051 - val_mae: 0.8267 - lr: 2.5000e-04\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9774 - mae: 0.7710 - val_loss: 1.1052 - val_mae: 0.8269 - lr: 2.5000e-04\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9809 - mae: 0.7715 - val_loss: 1.1041 - val_mae: 0.8265 - lr: 2.5000e-04\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9735 - mae: 0.7712 - val_loss: 1.1032 - val_mae: 0.8263 - lr: 2.5000e-04\n",
            "Epoch 59/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 0.9806 - mae: 0.7712\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9793 - mae: 0.7712 - val_loss: 1.1022 - val_mae: 0.8260 - lr: 2.5000e-04\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9797 - mae: 0.7711 - val_loss: 1.1052 - val_mae: 0.8267 - lr: 1.2500e-04\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9802 - mae: 0.7704 - val_loss: 1.1050 - val_mae: 0.8267 - lr: 1.2500e-04\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9747 - mae: 0.7704 - val_loss: 1.1055 - val_mae: 0.8267 - lr: 1.2500e-04\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9754 - mae: 0.7705 - val_loss: 1.1050 - val_mae: 0.8266 - lr: 1.2500e-04\n",
            "Epoch 64/100\n",
            "25/29 [========================>.....] - ETA: 0s - loss: 0.9779 - mae: 0.7724\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9748 - mae: 0.7706 - val_loss: 1.1039 - val_mae: 0.8263 - lr: 1.2500e-04\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9766 - mae: 0.7705 - val_loss: 1.1050 - val_mae: 0.8265 - lr: 6.2500e-05\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.9815 - mae: 0.7706Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9815 - mae: 0.7706 - val_loss: 1.1052 - val_mae: 0.8265 - lr: 6.2500e-05\n",
            "Epoch 00066: early stopping\n",
            "fold 9\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 1.2979 - mae: 0.9020 - val_loss: 1.1255 - val_mae: 0.8155 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1800 - mae: 0.8556 - val_loss: 1.1039 - val_mae: 0.8074 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.1086 - mae: 0.8299 - val_loss: 1.0863 - val_mae: 0.8013 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0686 - mae: 0.8152 - val_loss: 1.0795 - val_mae: 0.7991 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0462 - mae: 0.8024 - val_loss: 1.0777 - val_mae: 0.7987 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0337 - mae: 0.7987 - val_loss: 1.0770 - val_mae: 0.7986 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0228 - mae: 0.7939 - val_loss: 1.0765 - val_mae: 0.7985 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0215 - mae: 0.7915 - val_loss: 1.0761 - val_mae: 0.7985 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0180 - mae: 0.7904 - val_loss: 1.0759 - val_mae: 0.7985 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 1.0122 - mae: 0.7892 - val_loss: 1.0757 - val_mae: 0.7985 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0104 - mae: 0.7880 - val_loss: 1.0754 - val_mae: 0.7985 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0075 - mae: 0.7864 - val_loss: 1.0751 - val_mae: 0.7984 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0043 - mae: 0.7866 - val_loss: 1.0748 - val_mae: 0.7983 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0132 - mae: 0.7863 - val_loss: 1.0748 - val_mae: 0.7984 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0044 - mae: 0.7852 - val_loss: 1.0744 - val_mae: 0.7982 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0049 - mae: 0.7852 - val_loss: 1.0759 - val_mae: 0.7989 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0030 - mae: 0.7837 - val_loss: 1.0748 - val_mae: 0.7988 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0024 - mae: 0.7837 - val_loss: 1.0774 - val_mae: 0.8001 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0066 - mae: 0.7818 - val_loss: 1.0792 - val_mae: 0.8020 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0038 - mae: 0.7825 - val_loss: 1.0811 - val_mae: 0.8025 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0002 - mae: 0.7820 - val_loss: 1.0872 - val_mae: 0.8045 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 1.0008 - mae: 0.7824\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 1.0029 - mae: 0.7827 - val_loss: 1.0883 - val_mae: 0.8063 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9976 - mae: 0.7814 - val_loss: 1.0928 - val_mae: 0.8074 - lr: 5.0000e-04\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9956 - mae: 0.7805 - val_loss: 1.0903 - val_mae: 0.8062 - lr: 5.0000e-04\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9927 - mae: 0.7806 - val_loss: 1.0923 - val_mae: 0.8067 - lr: 5.0000e-04\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9953 - mae: 0.7803 - val_loss: 1.0929 - val_mae: 0.8071 - lr: 5.0000e-04\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9929 - mae: 0.7798 - val_loss: 1.0994 - val_mae: 0.8102 - lr: 5.0000e-04\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9970 - mae: 0.7796 - val_loss: 1.1043 - val_mae: 0.8114 - lr: 5.0000e-04\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9907 - mae: 0.7788 - val_loss: 1.0987 - val_mae: 0.8084 - lr: 5.0000e-04\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9947 - mae: 0.7789 - val_loss: 1.0932 - val_mae: 0.8065 - lr: 5.0000e-04\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9927 - mae: 0.7795 - val_loss: 1.1052 - val_mae: 0.8111 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9928 - mae: 0.7792\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9959 - mae: 0.7793 - val_loss: 1.1044 - val_mae: 0.8111 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9904 - mae: 0.7786 - val_loss: 1.1023 - val_mae: 0.8096 - lr: 2.5000e-04\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9939 - mae: 0.7787 - val_loss: 1.0988 - val_mae: 0.8082 - lr: 2.5000e-04\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9941 - mae: 0.7787 - val_loss: 1.1025 - val_mae: 0.8099 - lr: 2.5000e-04\n",
            "Epoch 36/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 0.9922 - mae: 0.7788\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9925 - mae: 0.7785 - val_loss: 1.0999 - val_mae: 0.8092 - lr: 2.5000e-04\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9899 - mae: 0.7772 - val_loss: 1.1019 - val_mae: 0.8101 - lr: 1.2500e-04\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9930 - mae: 0.7777 - val_loss: 1.1031 - val_mae: 0.8103 - lr: 1.2500e-04\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9946 - mae: 0.7770 - val_loss: 1.1028 - val_mae: 0.8103 - lr: 1.2500e-04\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.9927 - mae: 0.7779 - val_loss: 1.1018 - val_mae: 0.8099 - lr: 1.2500e-04\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.9908 - mae: 0.7775 - val_loss: 1.1049 - val_mae: 0.8109 - lr: 1.2500e-04\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9865 - mae: 0.7767 - val_loss: 1.1042 - val_mae: 0.8105 - lr: 1.2500e-04\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9928 - mae: 0.7774 - val_loss: 1.1033 - val_mae: 0.8100 - lr: 1.2500e-04\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.9889 - mae: 0.7774 - val_loss: 1.1031 - val_mae: 0.8100 - lr: 1.2500e-04\n",
            "Epoch 45/100\n",
            "28/29 [===========================>..] - ETA: 0s - loss: 0.9914 - mae: 0.7779\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9930 - mae: 0.7779 - val_loss: 1.1034 - val_mae: 0.8103 - lr: 1.2500e-04\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9965 - mae: 0.7773 - val_loss: 1.1028 - val_mae: 0.8101 - lr: 6.2500e-05\n",
            "Epoch 47/100\n",
            "27/29 [==========================>...] - ETA: 0s - loss: 0.9893 - mae: 0.7764Restoring model weights from the end of the best epoch.\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.9885 - mae: 0.7772 - val_loss: 1.1024 - val_mae: 0.8099 - lr: 6.2500e-05\n",
            "Epoch 00047: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya4HOjvhUCVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_case_for_drug = model.get_layer('use_case_for_drug').get_weights()[0]\n",
        "name_of_drug = model.get_layer('name_of_drug').get_weights()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqLojR4KU2aK",
        "colab_type": "code",
        "outputId": "d97bdff5-6b42-446f-ddcb-5a390d8ba3d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(data.use_case_for_drug.unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "670"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_sNca76VOmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "saved_embeddings_fname = \"/content/drive/My Drive/embeddings.pickle\"\n",
        "with open(saved_embeddings_fname, 'wb') as f:\n",
        "    pickle.dump([use_case_for_drug,name_of_drug], f, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_FDFdPEJqzo",
        "colab_type": "code",
        "outputId": "6a2ab303-1826-4aff-e3e9-4d6b47d6ae57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "test_preds/10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02912089, 0.02415028, 0.13070462, ..., 0.00073672, 0.0058581 ,\n",
              "       0.11667352])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqLPQflRLN5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = qt.inverse_transform(test_preds.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HLqxsAwL1ss",
        "colab_type": "code",
        "outputId": "4dc930f0-695e-468e-f3ac-c3ac37c91e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "test_preds.ravel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.21451693, 7.17099722, 8.59389419, ..., 6.80935728, 6.90164144,\n",
              "       8.49878707])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_kUjlKgOPFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv('/content/drive/My Drive/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8iSy45SOql3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub['base_score'] = pd.Series(test_preds.ravel())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUaNCySpOrWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub[['patient_id','base_score']].to_csv('stdai1.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNEWEFAsPFKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}